# -*- coding: utf-8 -*-
"""Trafficsign.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n4agNccmOEfcKu_-Ishh6I0bspqdL2En
"""

# Mount Google Drive to access files
from google.colab import drive
drive.mount('/content/drive')

import os

# Set the dataset directory path to the archive folder in your Google Drive
dataset_dir = '/content/drive/MyDrive/archive'

# List all files and subfolders in the dataset directory
for root, dirs, files in os.walk(dataset_dir):
    print(f'Current directory: {root}')
    print(f'Subdirectories: {dirs}')
    print(f'Files: {files}')
    print('-' * 50)

import os

# List the contents of the dataset directory
dataset_dir = '/content/dataset'

for root, dirs, files in os.walk(dataset_dir):
    print(f'Directory: {root}')
    print(f'Contains: {len(files)} files')
    print('---')

import os
import matplotlib.pyplot as plt
import cv2

# Correct dataset directory path
dataset_dir = '/content/drive/MyDrive/archive'  # ‚úÖ Update this path

# Function to display images
def display_images(image_paths):
    plt.figure(figsize=(10, 10))
    for i, img_path in enumerate(image_paths):
        img = cv2.imread(img_path)
        if img is not None:
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            plt.subplot(3, 3, i + 1)
            plt.imshow(img)
            plt.axis('off')
        else:
            print(f"‚ö†Ô∏è Could not load image: {img_path}")
    plt.tight_layout()
    plt.show()

# Check available class folders
print("Available folders in dataset:")
train_dir = os.path.join(dataset_dir, 'Train')  # ‚úÖ This now becomes /content/drive/MyDrive/archive/Train

if os.path.exists(train_dir):
    class_folders = os.listdir(train_dir)
    print(class_folders)

    # Display images from the first class folder
    if class_folders:
        example_class_dir = os.path.join(train_dir, class_folders[0])

        example_images = [os.path.join(example_class_dir, img)
                          for img in os.listdir(example_class_dir)[:9]
                          if img.lower().endswith(('.jpg', '.jpeg', '.png'))]

        display_images(example_images)
    else:
        print(f"‚ö†Ô∏è No class folders found in {train_dir}")

else:
    print(f"‚ö†Ô∏è Training directory not found at {train_dir}")

import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define image size and batch size
img_height, img_width = 64, 64
batch_size = 32

# ‚úÖ Correct dataset path
dataset_dir = '/content/drive/MyDrive/archive/Train'

# Create ImageDataGenerator for data augmentation
datagen = ImageDataGenerator(
    rescale=1. / 255,
    validation_split=0.2  # 20% for validation
)

# Load training data
train_data = datagen.flow_from_directory(
    dataset_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training',
    shuffle=True
)

# Load validation data
validation_data = datagen.flow_from_directory(
    dataset_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation',
    shuffle=True
)

from tensorflow.keras import layers, models

# Define the CNN model
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
    layers.MaxPooling2D(pool_size=(2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2, 2)),

    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D(pool_size=(2, 2)),

    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(len(train_data.class_indices), activation='softmax')  # Output layer with softmax
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

import os

# Define the valid image extensions
valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')

# ‚úÖ Correct dataset directory path
dataset_dir = '/content/drive/MyDrive/archive/Train'

# Clean dataset: remove non-image files from all class folders
for class_dir in os.listdir(dataset_dir):
    class_path = os.path.join(dataset_dir, class_dir)
    if os.path.isdir(class_path):
        for filename in os.listdir(class_path):
            file_path = os.path.join(class_path, filename)

            if os.path.isfile(file_path) and not filename.lower().endswith(valid_extensions):
                print(f"‚ùå Removing non-image file: {file_path}")
                os.remove(file_path)

from PIL import Image
import os

def is_image_valid(file_path):
    try:
        with Image.open(file_path) as img:
            img.verify()
        return True
    except Exception:
        return False

dataset_dir = '/content/drive/MyDrive/archive/Train'

checked = 0
max_images_to_check = 100  # üîÅ Change or remove this to check more/all images

for class_dir in os.listdir(dataset_dir):
    class_path = os.path.join(dataset_dir, class_dir)
    if os.path.isdir(class_path):
        for filename in os.listdir(class_path):
            file_path = os.path.join(class_path, filename)
            if os.path.isfile(file_path):
                checked += 1
                print(f"üîç Checking ({checked}): {file_path}")

                if not is_image_valid(file_path):
                    print(f"‚ùå Deleting corrupted image: {file_path}")
                    os.remove(file_path)

                if checked >= max_images_to_check:
                    print("‚úÖ Finished checking test batch.")
                    break  # Remove this break if you want to process all

# Recreate the generators
train_data = datagen.flow_from_directory(
    dataset_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_data = datagen.flow_from_directory(
    dataset_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

# Train the model
history = model.fit(
    train_data,
    validation_data=validation_data,
    epochs=10
)

loss, accuracy = model.evaluate(validation_data)
print(f"\nüìä Final Validation Accuracy: {accuracy:.4f}")

import matplotlib.pyplot as plt

# Accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

print(f"Final Training Accuracy: {history.history['accuracy'][-1] * 100:.2f}%")
print(f"Final Validation Accuracy: {history.history['val_accuracy'][-1] * 100:.2f}%")

model.save('traffic_sign_cnn_model.keras')  # ‚úÖ Modern format

from tensorflow.keras.models import load_model

model = load_model('traffic_sign_cnn_model.keras')

import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
import os

# Path to your saved model
model_path = '/content/drive/MyDrive/traffic_sign_cnn_model.keras'  # or .h5 if saved in old format

# Load the trained model
model = load_model('/content/traffic_sign_cnn_model.keras')

# Path to your image for testing
test_image_path = '/content/drive/MyDrive/archive/Class_0/sample.jpg'  # Replace with your image path

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import os

# ‚úÖ Step 1: Set image size and model path
img_height, img_width = 64, 64
model_path = '/content/traffic_sign_cnn_model.keras'  # updated model path

# ‚úÖ Step 2: Load the trained model
model = load_model(model_path)

# ‚úÖ Step 3: Define path to a test image in the Meta folder
# Use os.listdir to list actual files
meta_folder = '/content/drive/MyDrive/archive/Meta'
test_image_name = os.listdir(meta_folder)[4]  # pick the first image automatically
test_image_path = os.path.join(meta_folder, test_image_name)

# ‚úÖ Step 4: Load and preprocess the image
img = image.load_img(test_image_path, target_size=(img_height, img_width))
img_array = image.img_to_array(img) / 255.0  # normalize
img_array = np.expand_dims(img_array, axis=0)  # add batch dimension

# ‚úÖ Step 5: Predict
prediction = model.predict(img_array)
predicted_class = np.argmax(prediction)

# ‚úÖ Step 6: Get class label (optional - only if train_data is available)
# If train_data.class_indices is NOT available, skip this part or manually create a label map
try:
    label_map = {v: k for k, v in train_data.class_indices.items()}
    predicted_label = label_map[predicted_class]
except:
    predicted_label = f"Class_{predicted_class}"  # fallback if class_indices are not available

# ‚úÖ Step 7: Show results
print(f"üì∏ File tested: {test_image_name}")
print(f"‚úÖ Predicted class index: {predicted_class}")
print(f"üè∑Ô∏è Predicted class label: {predicted_label}")

# ‚úÖ Step 8: Display the image
plt.imshow(img)
plt.title(f"Predicted: {predicted_label}")
plt.axis('off')
plt.show()

# Loop through all images in the Meta folder
for test_image_name in os.listdir(meta_folder):
    test_image_path = os.path.join(meta_folder, test_image_name)

    try:
        img = image.load_img(test_image_path, target_size=(img_height, img_width))
        img_array = image.img_to_array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        prediction = model.predict(img_array)
        predicted_class = np.argmax(prediction)

        try:
            label_map = {v: k for k, v in train_data.class_indices.items()}
            predicted_label = label_map[predicted_class]
        except:
            predicted_label = f"Class_{predicted_class}"

        print(f"{test_image_name} --> Predicted: {predicted_label}")

    except Exception as e:
        print(f"‚ùå Error processing {test_image_name}: {e}")

import pandas as pd

results = []

for test_image_name in os.listdir(meta_folder):
    test_image_path = os.path.join(meta_folder, test_image_name)

    try:
        img = image.load_img(test_image_path, target_size=(img_height, img_width))
        img_array = image.img_to_array(img) / 255.0
        img_array = np.expand_dims(img_array, axis=0)

        prediction = model.predict(img_array)
        predicted_class = np.argmax(prediction)

        try:
            label_map = {v: k for k, v in train_data.class_indices.items()}
            predicted_label = label_map[predicted_class]
        except:
            predicted_label = f"Class_{predicted_class}"

        results.append({"Image": test_image_name, "Predicted Label": predicted_label})

    except Exception as e:
        results.append({"Image": test_image_name, "Predicted Label": f"Error: {e}"})

# Save to CSV
df = pd.DataFrame(results)
df.to_csv('/content/predictions.csv', index=False)
print("‚úÖ Predictions saved to predictions.csv")

import matplotlib.pyplot as plt

# Accuracy plot
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Loss plot
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# prompt: model accuracy and model loss in percentage

# Print final training and validation accuracy and loss in percentage
print(f"Final Training Accuracy: {history.history['accuracy'][-1] * 100:.2f}%")
print(f"Final Validation Accuracy: {history.history['val_accuracy'][-1] * 100:.2f}%")
print(f"Final Training Loss: {history.history['loss'][-1] * 100:.2f}%")
print(f"Final Validation Loss: {history.history['val_loss'][-1] * 100:.2f}%")

model.save('/content/drive/MyDrive/traffic_sign_model_final.keras')